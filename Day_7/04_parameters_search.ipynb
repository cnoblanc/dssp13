{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fetch the \"titanic\" dataset directly from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the missing values are stored with the following character `\"?\"`. We will notify it to Pandas when reading the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://www.openml.org/data/get_csv/16826755/phpMYEkMl.csv\",\n",
    "    na_values='?'\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification task is to predict whether or not a person will survive the Titanic disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df.drop(columns='survived')\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The typical machine-learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The titanic dataset is composed of mixed data types (i.e. numerical and categorical data). Therefore, we need to define a preprocessing pipeline for each data type and use a `ColumnTransformer` to process each type separetely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define the different column depending of their data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'fare']\n",
    "cat_col = ['sex', 'embarked', 'pclass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define the two preprocessing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# some of the categories will be rare and we need to\n",
    "# specify the categories in advance\n",
    "categories = [X_df[column].unique() for column in X_df[cat_col]]\n",
    "for cat in categories:\n",
    "    for idx, elt in enumerate(cat):\n",
    "        if not isinstance(elt, str) and np.isnan(elt):\n",
    "            cat[idx] = 'missing'\n",
    "\n",
    "# define the pipelines\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(categories=categories)\n",
    ")\n",
    "# Pour les colonnes numériques :\n",
    "num_pipe = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both preprocessing using a `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessing = ColumnTransformer(\n",
    "    [('cat_preprocessor', cat_pipe, cat_col),\n",
    "     ('num_preprocessor', num_pipe, num_cols)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   3.        ,   2.        ,  29.96344847,\n",
       "          7.7333    ],\n",
       "       [  0.        ,   3.        ,   2.        ,  29.96344847,\n",
       "          7.75      ],\n",
       "       [  0.        ,   1.        ,   2.        ,  38.        ,\n",
       "          7.2292    ],\n",
       "       ...,\n",
       "       [  1.        ,   0.        ,   1.        ,  34.        ,\n",
       "         13.        ],\n",
       "       [  1.        ,   0.        ,   2.        ,  22.        ,\n",
       "          8.05      ],\n",
       "       [  0.        ,   0.        ,   0.        ,   2.        ,\n",
       "        151.55      ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.fit_transform(X_train)\n",
    "# On retrouve le codage des categories d'abord, puis les 2 derniers sont les valeurs numériques\n",
    "# Car on l'a mis en seconde position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create a pipeline made of the preprocessor and a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophenoblanc/anaconda3/envs/dssp/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "_=model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835365853658537"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine-learning algorithms rely on parameters which will affect the performance of the final model. Scikit-learn provides default values for these parameters. However, using these default parameters does not necessarily lead to the a model with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set some parameters which will may change the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessing',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('cat_preprocessor',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(add_indicator=False,\n",
       "                                                                   copy=True,\n",
       "                                                                   fill_value='missing',\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='constant',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('ordinalencoder',\n",
       "                                                     OrdinalEncoder(categories=[array(['female', 'male'], dtype=object),\n",
       "                                                                                array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "                                                                                array([1, 2, 3])],\n",
       "                                                                    dtype=<class 'numpy.float64'>))],\n",
       "                                             verbose=False),\n",
       "                                    ['sex', 'embarked', 'pclass']),\n",
       "                                   ('num_preprocessor',\n",
       "                                    SimpleImputer(add_indicator=False, copy=True,\n",
       "                                                  fill_value=None,\n",
       "                                                  missing_values=nan,\n",
       "                                                  strategy='mean', verbose=0),\n",
       "                                    ['age', 'fare'])],\n",
       "                     verbose=False)),\n",
       "  ('clf',\n",
       "   RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                          oob_score=False, random_state=42, verbose=0,\n",
       "                          warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'preprocessing': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('cat_preprocessor',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                 copy=True,\n",
       "                                                                 fill_value='missing',\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='constant',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('ordinalencoder',\n",
       "                                                   OrdinalEncoder(categories=[array(['female', 'male'], dtype=object),\n",
       "                                                                              array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "                                                                              array([1, 2, 3])],\n",
       "                                                                  dtype=<class 'numpy.float64'>))],\n",
       "                                           verbose=False),\n",
       "                                  ['sex', 'embarked', 'pclass']),\n",
       "                                 ('num_preprocessor',\n",
       "                                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                                fill_value=None,\n",
       "                                                missing_values=nan,\n",
       "                                                strategy='mean', verbose=0),\n",
       "                                  ['age', 'fare'])],\n",
       "                   verbose=False),\n",
       " 'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                        oob_score=False, random_state=42, verbose=0,\n",
       "                        warm_start=False),\n",
       " 'preprocessing__n_jobs': None,\n",
       " 'preprocessing__remainder': 'drop',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('cat_preprocessor', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True,\n",
       "                                  fill_value='missing', missing_values=nan,\n",
       "                                  strategy='constant', verbose=0)),\n",
       "                   ('ordinalencoder',\n",
       "                    OrdinalEncoder(categories=[array(['female', 'male'], dtype=object),\n",
       "                                               array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "                                               array([1, 2, 3])],\n",
       "                                   dtype=<class 'numpy.float64'>))],\n",
       "            verbose=False), ['sex', 'embarked', 'pclass']),\n",
       "  ('num_preprocessor',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                 missing_values=nan, strategy='mean', verbose=0),\n",
       "   ['age', 'fare'])],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__cat_preprocessor': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                fill_value='missing', missing_values=nan,\n",
       "                                strategy='constant', verbose=0)),\n",
       "                 ('ordinalencoder',\n",
       "                  OrdinalEncoder(categories=[array(['female', 'male'], dtype=object),\n",
       "                                             array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "                                             array([1, 2, 3])],\n",
       "                                 dtype=<class 'numpy.float64'>))],\n",
       "          verbose=False),\n",
       " 'preprocessing__num_preprocessor': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='mean', verbose=0),\n",
       " 'preprocessing__cat_preprocessor__memory': None,\n",
       " 'preprocessing__cat_preprocessor__steps': [('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value='missing',\n",
       "                 missing_values=nan, strategy='constant', verbose=0)),\n",
       "  ('ordinalencoder',\n",
       "   OrdinalEncoder(categories=[array(['female', 'male'], dtype=object),\n",
       "                              array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "                              array([1, 2, 3])],\n",
       "                  dtype=<class 'numpy.float64'>))],\n",
       " 'preprocessing__cat_preprocessor__verbose': False,\n",
       " 'preprocessing__cat_preprocessor__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value='missing',\n",
       "               missing_values=nan, strategy='constant', verbose=0),\n",
       " 'preprocessing__cat_preprocessor__ordinalencoder': OrdinalEncoder(categories=[array(['female', 'male'], dtype=object),\n",
       "                            array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "                            array([1, 2, 3])],\n",
       "                dtype=<class 'numpy.float64'>),\n",
       " 'preprocessing__cat_preprocessor__simpleimputer__add_indicator': False,\n",
       " 'preprocessing__cat_preprocessor__simpleimputer__copy': True,\n",
       " 'preprocessing__cat_preprocessor__simpleimputer__fill_value': 'missing',\n",
       " 'preprocessing__cat_preprocessor__simpleimputer__missing_values': nan,\n",
       " 'preprocessing__cat_preprocessor__simpleimputer__strategy': 'constant',\n",
       " 'preprocessing__cat_preprocessor__simpleimputer__verbose': 0,\n",
       " 'preprocessing__cat_preprocessor__ordinalencoder__categories': [array(['female', 'male'], dtype=object),\n",
       "  array(['S', 'C', 'missing', 'Q'], dtype=object),\n",
       "  array([1, 2, 3])],\n",
       " 'preprocessing__cat_preprocessor__ordinalencoder__dtype': numpy.float64,\n",
       " 'preprocessing__num_preprocessor__add_indicator': False,\n",
       " 'preprocessing__num_preprocessor__copy': True,\n",
       " 'preprocessing__num_preprocessor__fill_value': None,\n",
       " 'preprocessing__num_preprocessor__missing_values': nan,\n",
       " 'preprocessing__num_preprocessor__strategy': 'mean',\n",
       " 'preprocessing__num_preprocessor__verbose': 0,\n",
       " 'clf__bootstrap': True,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 'auto',\n",
       " 'clf__max_leaf_nodes': None,\n",
       " 'clf__min_impurity_decrease': 0.0,\n",
       " 'clf__min_impurity_split': None,\n",
       " 'clf__min_samples_leaf': 1,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__n_estimators': 10,\n",
       " 'clf__n_jobs': -1,\n",
       " 'clf__oob_score': False,\n",
       " 'clf__random_state': 42,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on veut modifier un paramètre du classifier (random forest ici),\n",
    "# Il suffit de faire un \"set\" du paramètre qui commence par \"clf__...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data: 0.757\n",
      "Accuracy score on the testing data: 0.762\n"
     ]
    }
   ],
   "source": [
    "# Par exemple, ici, on veut modifier 2 paramètres : clf__n_estimators & clf__max_depth\n",
    "model.set_params(clf__n_estimators=2, clf__max_depth=2)\n",
    "_ = model.fit(X_train, y_train)\n",
    "print(f'Accuracy score on the training data: '\n",
    "      f'{model.score(X_train, y_train):.3f}')\n",
    "print(f'Accuracy score on the testing data: '\n",
    "      f'{model.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>QUESTIONS</b>:</p>\n",
    "    <ul>\n",
    "    <li>By analyzing the training and testing scores, what can you say about the model? Is it under- or over-fitting?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case, it under-fit as the score on Train is not hight and Train is less than Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>QUESTIONS</b>:</p>\n",
    "    <ul>\n",
    "    <li>What if we don't limit the depth of the trees in the forest?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set : clf__max_depth=None\n",
    "# -> Over-fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>QUESTIONS</b>:</p>\n",
    "    <ul>\n",
    "    <li>And for the case where the forest is composed of a large number of deep trees and each tree has no depth limit?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf__n_estimators=150, clf__max_depth=None\n",
    "# Over-fit \n",
    "# Testing score : is still OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a grid-search instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous is really tedious and we are not sure to cover all possible cases. Instead, we could make an automatic search to discover all possible combination of hyper-parameters and check what would be the performance of the model. One tool for search exhaustive search is called `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With grid-search, we need to specify the set of values we wish to test. The `GridSearchCV` will create a grid with all the possible combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define all combinations of a list of hyper-parameters\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [5, 50, 100],\n",
    "    'clf__max_depth': [3, 5, 8, None]\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid=param_grid, n_jobs=-1, cv=5) \n",
    "# n_jobs : on va entrainer sur une partie des données (cross validation à l'intérieur)\n",
    "# cv=5 : Il va faire 5 fois le process train/test et prendre le score moyen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtain estimator is used as a normal estimator using `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessing',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat_preprocessor',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value='missing',\n",
       "                                                                                                        missing_...\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=2,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': [3, 5, 8, None],\n",
       "                         'clf__n_estimators': [5, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !! ne JAMAIS passer le jeu de TEST ici car on cherche à optimiser les hyper-paramètres du modèle\n",
    "# Donc, c'est sur seulement \"Train\" qu'on peut faire ça.\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the results of all combination by looking at the `cv_results_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.793068</td>\n",
       "      <td>0.008497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.792049</td>\n",
       "      <td>0.015524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.790010</td>\n",
       "      <td>0.017566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.787971</td>\n",
       "      <td>0.007024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.786952</td>\n",
       "      <td>0.016059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.021304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.011001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.782875</td>\n",
       "      <td>0.023322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.018933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.027918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.766565</td>\n",
       "      <td>0.020622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.765545</td>\n",
       "      <td>0.018998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_clf__max_depth param_clf__n_estimators  mean_test_score  \\\n",
       "7                     8                      50         0.793068   \n",
       "8                     8                     100         0.792049   \n",
       "5                     5                     100         0.790010   \n",
       "10                 None                      50         0.787971   \n",
       "3                     5                       5         0.786952   \n",
       "4                     5                      50         0.785933   \n",
       "11                 None                     100         0.785933   \n",
       "6                     8                       5         0.782875   \n",
       "2                     3                     100         0.779817   \n",
       "1                     3                      50         0.773700   \n",
       "9                  None                       5         0.766565   \n",
       "0                     3                       5         0.765545   \n",
       "\n",
       "    std_test_score  \n",
       "7         0.008497  \n",
       "8         0.015524  \n",
       "5         0.017566  \n",
       "10        0.007024  \n",
       "3         0.016059  \n",
       "4         0.021304  \n",
       "11        0.011001  \n",
       "6         0.023322  \n",
       "2         0.018933  \n",
       "1         0.027918  \n",
       "9         0.020622  \n",
       "0         0.018998  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(grid.cv_results_)\n",
    "columns_to_keep = [\n",
    "    'param_clf__max_depth',\n",
    "    'param_clf__n_estimators',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "]\n",
    "df_results = df_results[columns_to_keep]\n",
    "df_results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 8, 'clf__n_estimators': 50}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7930682976554536"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>QUESTIONS</b>:</p>\n",
    "    <ul>\n",
    "    <li>What might be a limitation of using a grid-search with several parmaters and several values for each parameter?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could miss a optimized combination (it depend on the list of values defined before)\n",
    "# et plus on ajoute des cas, plus le nb de combinaison augmente, ça explose le temps de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the `RandomizedSearchCV`. In this case, the parameters values will be drawn from some predefined distribution. Then, we will make some successive drawing anch check the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'clf__n_estimators': randint(1, 100),\n",
    "    'clf__max_depth': randint(2, 15),\n",
    "    'clf__max_features': [1, 2, 3, 4, 5],\n",
    "    'clf__min_samples_split': [2, 3, 4, 5, 10, 30],\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions,\n",
    "    n_iter=50, n_jobs=-1, cv=5, random_state=42\n",
    ")\n",
    "# n_iter : tirer 20 valeurs au hasard\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__min_samples_split</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802243</td>\n",
       "      <td>0.017158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.801223</td>\n",
       "      <td>0.013206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.801223</td>\n",
       "      <td>0.012806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.018712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.015688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_clf__n_estimators param_clf__max_depth param_clf__max_features  \\\n",
       "23                      60                    6                       2   \n",
       "32                      65                    9                       3   \n",
       "28                      33                    9                       3   \n",
       "4                       30                    6                       2   \n",
       "36                      77                   11                       2   \n",
       "\n",
       "   param_clf__min_samples_split  mean_test_score  std_test_score  \n",
       "23                            2         0.802243        0.017158  \n",
       "32                            4         0.801223        0.013206  \n",
       "28                            4         0.801223        0.012806  \n",
       "4                             5         0.798165        0.018712  \n",
       "36                            5         0.798165        0.015688  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(search.cv_results_)\n",
    "columns_to_keep = [\n",
    "    \"param_\" + param_name for param_name in param_distributions]\n",
    "columns_to_keep += [\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "]\n",
    "df_results = df_results[columns_to_keep]\n",
    "df_results = df_results.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__max_features</th>\n",
       "      <th>param_clf__min_samples_split</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.778797</td>\n",
       "      <td>0.017823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.772681</td>\n",
       "      <td>0.021707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769623</td>\n",
       "      <td>0.020003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.023637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.762487</td>\n",
       "      <td>0.024938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_clf__n_estimators param_clf__max_depth param_clf__max_features  \\\n",
       "10                      51                    5                       1   \n",
       "20                      14                    3                       2   \n",
       "31                      44                    2                       5   \n",
       "34                      14                    2                       5   \n",
       "6                       22                    2                       4   \n",
       "\n",
       "   param_clf__min_samples_split  mean_test_score  std_test_score  \n",
       "10                            4         0.778797        0.017823  \n",
       "20                           30         0.772681        0.021707  \n",
       "31                            4         0.769623        0.020003  \n",
       "34                            3         0.768603        0.023637  \n",
       "6                             3         0.762487        0.024938  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <p>Build a machine-learning pipeline using a <tt>HistGradientBoostingClassifier</tt> and fine tune your model on the Titanic dataset using a <tt>RandomizedSearchCV</tt>.</p>\n",
    "    <p>You may want to set the parameter distributions is the following manner:</p>\n",
    "    <ul>\n",
    "    <li><tt>learning_rate</tt> with values ranging from 0.001 to 0.5 following a reciprocal distribution.</li>\n",
    "    <li><tt>l2_regularization</tt> with values ranging from 0.0 to 0.5 following a uniform distribution.</li>\n",
    "    <li><tt>max_leaf_nodes</tt> with integer values ranging from 5 to 30 following a uniform distribution.</li>\n",
    "    <li><tt>min_samples_leaf</tt> with integer values ranging from 5 to 30 following a uniform distribution.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
